{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPm9KSaGlXP7t8XD6Coeiw0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import time\n","import requests\n","import pandas as pd\n","from tqdm import tqdm\n","from datetime import datetime, timedelta\n","\n","BASE_URL = \"https://api.hh.ru\"\n","\n","HEADERS = {\n","    \"User-Agent\": \"HSE-DataAnalyst-Project/1.0 (tg: @oa_sht)\"\n","}\n","\n","MOSCOW_AREA_ID = 1\n","\n","\n","def hh_get(url: str, params: dict | None = None, max_retries: int = 6) -> dict:\n","    for attempt in range(1, max_retries + 1):\n","        r = requests.get(url, headers=HEADERS, params=params, timeout=30)\n","        if r.status_code == 200:\n","            return r.json()\n","        if r.status_code in (429, 500, 502, 503, 504):\n","            retry_after = r.headers.get(\"Retry-After\")\n","            wait = float(retry_after) if retry_after else min(10.0, 0.5 * attempt)\n","            time.sleep(wait)\n","            continue\n","        raise RuntimeError(f\"HH API error {r.status_code}: {r.text[:500]}\")\n","    raise RuntimeError(f\"Failed after {max_retries} retries: {url}\")\n","\n","\n","def iso(dt: datetime) -> str:\n","    return dt.strftime(\"%Y-%m-%dT%H:%M:%S\")\n","\n","\n","def iter_day_windows(start_dt: datetime, end_dt: datetime):\n","    cur = start_dt\n","    while cur < end_dt:\n","        nxt = min(cur + timedelta(days=1), end_dt)\n","        yield cur, nxt\n","        cur = nxt\n","\n","\n","def search_ids(date_from_dt: datetime, date_to_dt: datetime, area: int = MOSCOW_AREA_ID,\n","               per_page: int = 100, max_pages: int = 200) -> list[str]:\n","    ids = []\n","    for page in range(max_pages):\n","        params = {\n","            \"text\": \" \",\n","            \"area\": area,\n","            \"per_page\": per_page,\n","            \"page\": page,\n","            \"date_from\": iso(date_from_dt),\n","            \"date_to\": iso(date_to_dt),\n","        }\n","        data = hh_get(f\"{BASE_URL}/vacancies\", params=params)\n","        items = data.get(\"items\", [])\n","        if not items:\n","            break\n","\n","        ids.extend(str(x[\"id\"]) for x in items)\n","\n","        pages_total = data.get(\"pages\")\n","        if pages_total is not None and page >= pages_total - 1:\n","            break\n","\n","        time.sleep(0.2)\n","\n","    return list(dict.fromkeys(ids))\n","\n","\n","def fetch_vacancy(vacancy_id: str) -> dict:\n","    return hh_get(f\"{BASE_URL}/vacancies/{vacancy_id}\")\n","\n","\n","def flatten(v: dict) -> dict:\n","    salary = v.get(\"salary\") or {}\n","    area = v.get(\"area\") or {}\n","    employer = v.get(\"employer\") or {}\n","    experience = v.get(\"experience\") or {}\n","    employment = v.get(\"employment\") or {}\n","    schedule = v.get(\"schedule\") or {}\n","\n","    roles = v.get(\"professional_roles\") or []\n","    role_names = [r.get(\"name\") for r in roles if r.get(\"name\")]\n","    main_role = role_names[0] if role_names else None\n","\n","    key_skills = v.get(\"key_skills\") or []\n","    skills = [s.get(\"name\") for s in key_skills if s.get(\"name\")]\n","\n","    return {\n","        \"id\": v.get(\"id\"),\n","        \"published_at\": v.get(\"published_at\"),\n","        \"name\": v.get(\"name\"),\n","        \"area_id\": area.get(\"id\"),\n","        \"area_name\": area.get(\"name\"),\n","        \"employer_id\": employer.get(\"id\"),\n","        \"employer_name\": employer.get(\"name\"),\n","        \"salary_from\": salary.get(\"from\"),\n","        \"salary_to\": salary.get(\"to\"),\n","        \"salary_currency\": salary.get(\"currency\"),\n","        \"salary_gross\": salary.get(\"gross\"),\n","        \"experience\": experience.get(\"id\"),\n","        \"employment\": employment.get(\"id\"),\n","        \"schedule\": schedule.get(\"id\"),\n","        \"professional_role_main\": main_role,\n","        \"professional_roles_all\": \", \".join(role_names) if role_names else None,\n","        \"key_skills\": \", \".join(skills) if skills else None,\n","        \"key_skills_count\": len(skills),\n","        \"description\": v.get(\"description\"),\n","        \"alternate_url\": v.get(\"alternate_url\"),\n","    }\n","\n","\n","def main():\n","    start = datetime(2026, 1, 20, 0, 0, 0)\n","    end = datetime(2026, 2, 3, 0, 0, 0)\n","\n","    all_ids = []\n","    print(\"Collecting vacancy IDs day-by-day...\")\n","    for d_from, d_to in iter_day_windows(start, end):\n","        ids = search_ids(d_from, d_to, area=MOSCOW_AREA_ID)\n","        all_ids.extend(ids)\n","        print(f\"{d_from.date()} -> {len(ids)} ids (cumulative {len(all_ids)})\")\n","        time.sleep(0.2)\n","\n","    all_ids = list(dict.fromkeys(all_ids))\n","    print(\"Unique vacancy IDs:\", len(all_ids))\n","\n","    rows = []\n","    errors = 0\n","    for vid in tqdm(all_ids, desc=\"Downloading vacancy details\"):\n","        try:\n","            rows.append(flatten(fetch_vacancy(vid)))\n","        except Exception as e:\n","            errors += 1\n","            print(f\"\\nFailed id={vid}: {e}\")\n","        time.sleep(0.2)\n","\n","    df = pd.DataFrame(rows)\n","    out = \"vacancies_moscow_last30days.csv\"\n","    df.to_csv(out, index=False, encoding=\"utf-8-sig\")\n","    print(f\"\\nSaved {df.shape[0]} rows, errors={errors} -> {out}\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"oEif3xj7BdGe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X26HNfQuO_MB","executionInfo":{"status":"ok","timestamp":1771258590780,"user_tz":-180,"elapsed":68093,"user":{"displayName":"Olga Shtoppel","userId":"10921411876069039331"}},"outputId":"35ba8476-2a47-407c-ff6b-7b509bbd3f87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","shutil.copy(\n","    \"vacancies_moscow_last30days.csv\",\n","    \"/content/drive/MyDrive/vacancies_moscow_last30days.csv\"\n",")\n"],"metadata":{"id":"xy4jX0X9PYfO","executionInfo":{"status":"ok","timestamp":1771258616927,"user_tz":-180,"elapsed":737,"user":{"displayName":"Olga Shtoppel","userId":"10921411876069039331"}},"outputId":"58d3cb35-4169-4fc5-b09d-d7dd6e4a6aa9","colab":{"base_uri":"https://localhost:8080/","height":36}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/vacancies_moscow_last30days.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]}]}